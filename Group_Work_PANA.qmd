---
bibliography: bio.bib
csl: harvard-cite-them-right.csl
title: Group Name's Group Project
execute:
  echo: false
  freeze: true
format:
  html:
    code-copy: true
    code-link: true
    toc: true
    toc-title: On this page
    toc-depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
  pdf:
    include-in-header:
      text: |
        \addtokomafont{disposition}{\rmfamily}
    mainfont: Spectral
    sansfont: "Roboto Flex"
    monofont: InputMonoCondensed
    papersize: a4
    geometry:
      - top=25mm
      - left=40mm
      - right=30mm
      - bottom=25mm
      - heightrounded
    toc: false
    number-sections: false
    colorlinks: true
    highlight-style: github
jupyter:
  jupytext:
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

## Declaration of Authorship {.unnumbered .unlisted}

We, PANA, pledge our honour that the work presented in this assessment is our own. Where information has been derived from other sources, we confirm that this has been indicated in the work. Where a Large Language Model such as ChatGPT has been used we confirm that we have made its contribution to the final submission clear.

Date:30—11-24

Student Numbers: 

## Brief Group Reflection

| What Went Well | What Was Challenging |
| -------------- | -------------------- |
| A              | The acquisition of historical open-source data is restricted. It can only be obtained through "Index of /~jreades/data". Although it is sufficient, the snapshots are not taken at the same fixed time each year.                    |
| C              | D                    |

## Priorities for Feedback

Are there any areas on which you would appreciate more detailed feedback if we're able to offer it?

{{< pagebreak >}}

# Response to Questions

See the raw file for examples of how to hide computational output as there is code hidden here.

```{python}
#| echo: False
import os
import pandas as pd
```

```{python}
#| echo: False
host = 'https://orca.casa.ucl.ac.uk'
path = '~jreades/data'
file = '20240614-London-listings.parquet'

if os.path.exists(file):
  df = pd.read_parquet(file)
else: 
  df = pd.read_parquet(f'{host}/{path}/{file}')
  df.to_parquet(file)
```

## 1. Who collected the InsideAirbnb data?

InsideAirbnb data is primarily collected by founders Murray Cox and Tom Slee. Murray is a community artist and activist and Tom is a former Airbnb host and a researcher. Key collaborators may have also contributed to collecting the data such as Taylor Higgins, Alice Corona, Michael Mintz, and Anya Sophe Behn. 

::: {.duedate}

( 2 points; Answer due Week 7 )

:::

An inline citation example: As discussed on @insideairbnb, there are many...

A parenthetical citation example: There are many ways to research Airbnb [see, for example, @insideairbnb]... 

## 2. Why did they collect the InsideAirbnb data?
Murray Cox was motivated to start collecting the data in 2014 while studying gentrification in Brooklyn, the project expanded to analyse Airbnb’s hidden effects in cities like New York and San Francisco. Cox and Slee, aligned in opposing Airbnb's portrayal of public data, gathered InsideAirbnb data to expose illegal renting and its negative housing market impacts. They sought to reveal the “lies” in Airbnb’s claims, with data proving evidence of scofflaws (Katz 2017). Cox also disputed Airbnb's claim that 87% of hosts rent out their primary homes (Lehr 2015). The data was collected to counter biased narratives, offering independent, open-access insights beyond Airbnb’s statistics or commercial providers.

::: {.duedate}

( 4 points; Answer due Week 7 )

:::

```{python}
#| output: asis
print(f"One of way to embed output in the text looks like this: after cleaning, we were left with {df.shape[0]:,} rows of data.")
```

This way is also supposed to work (`{python} f"{df.shape[0]:,}" `) but I've found it less reliable.

```{python}
ax = df.host_listings_count.plot.hist(bins=50);
ax.set_xlim([0,500]);
```

## 3. How was the InsideAirbnb data collected?  
The InsideAirbnb data was collected using automated web scraping, a method where scripts extract information from Airbnb's website by parsing its HTML content. Collaborator Michael "Ziggy" Mintz automated the scraping process (InsideAirbnb website), while Murray Cox compiled, analysed, and built the platform. Python scripts were used to collect snapshots of public data via the Airbnb website periodically, replacing older data for each location (Alsudais 2021). In the first stage, they browsed the Airbnb website to look for All listings within a city. If any listing was not visible. Then, in the second stage, the program would visit the page of each listing to collect the detailed information of that listing (Cox and Slee, 2016).

::: {.duedate}

( 5 points; Answer due Week 8 )

:::

## 4. How does the method of collection impact the completeness and/or accuracy of the InsideAirbnb data set's representation of the process it seeks to study, and what wider issues does this raise?
The data collection method employed by InsideAirbnb, which relies on automated web scraping, affects both the completeness and accuracy of its dataset. By capturing a snapshot of publicly available information at a specific moment, it overlooks temporal factors such as seasonal trends and changing guest preferences. Furthermore, the dataset excludes guest feedback, including reviews and ratings, limiting its analytical utility. Modifications to listings after data collection, the inability to differentiate between booked and unavailable nights, and Airbnb’s anonymisation policies—which can shift locations by up to 150 metres—skew key metrics like availability and occupancy rates (Alsudais, 2021).
Reliance on web scraping introduces further limitations, including assumptions about review-to-booking ratios or average stay durations, which may not reflect actual behaviours. Issues such as mislinked data, for example, a Los Angeles property erroneously connected to a Tokyo experience, highlight the risks of inaccuracies. Additionally, structural changes to Airbnb’s website necessitate ongoing monitoring to maintain data reliability.
The absence of Airbnb's raw data exacerbates these limitations, restricting access to detailed booking records, guest demographics, and host behaviour over time. Without this proprietary data, researchers face challenges in conducting comprehensive analyses of pricing strategies, socio-economic impacts, and market trends. This lack of granularity can result in incomplete or misleading findings when applied to housing policy or urban planning (Alsudais, 2021).
InsideAirbnb’s reliance on Airbnb’s platform introduces vulnerabilities, including periodic anonymisation of location data, which compromises reproducibility. Despite its widespread use, the dataset has undergone limited independent validation, raising concerns about its reliability and broader impact. Ethical issues regarding data accessibility, privacy, and validity further complicate its application in urban development and policy-making, emphasising the need for robust validation and transparency in data collection.

::: {.duedate}

( 11 points; Answer due Week 9 )

:::

## 5. What ethical considerations does the use of the InsideAirbnb data raise? 

::: {.duedate}

( 18 points; Answer due {{< var assess.group-date >}} )

:::

## 6. With reference to the InsideAirbnb data (*i.e.* using numbers, figures, maps, and descriptive statistics), what does an analysis of Hosts and Listing types suggest about the nature of Airbnb lets in London? 

::: {.duedate}

( 15 points; Answer due {{< var assess.group-date >}} )

:::

## 7. Drawing on your previous answers, and supporting your response with evidence (*e.g.* figures, maps, EDA/ESDA, and simple statistical analysis/models drawing on experience from, e.g., CASA0007), how *could* the InsideAirbnb data set be used to inform the regulation of Short-Term Lets (STL) in London? 

::: {.duedate}

( 45 points; Answer due {{< var assess.group-date >}} )

:::

## Sustainable Authorship Tools

Using the Terminal in Docker, you compile the Quarto report using `quarto render <group_submission_file>.qmd`.

Your QMD file should automatically download your BibTeX and CLS files and any other required files. If this is done right after library loading then the entire report should output successfully.

Written in Markdown and generated from [Quarto](https://quarto.org/). Fonts used: [Spectral](https://fonts.google.com/specimen/Spectral) (mainfont), [Roboto](https://fonts.google.com/specimen/Roboto) (<span style="font-family:Sans-Serif;">sansfont</span>) and [JetBrains Mono](https://fonts.google.com/specimen/JetBrains%20Mono) (`monofont`). 

## References
